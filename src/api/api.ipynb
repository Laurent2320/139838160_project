{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastapi\n",
    "# !pip install uvicorn\n",
    "# !pip install pandas\n",
    "# !pip install google-cloud-storage\n",
    "\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.responses import JSONResponse\n",
    "import tensorflow as tf\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the ZIP file\n",
    "url = \"https://media.fdj.fr/static-draws/csv/euromillions/euromillions_202002.zip\"\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Open a file-like object\n",
    "    zip_file = io.BytesIO(response.content)\n",
    "    # Extract the contents of the ZIP file\n",
    "    with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "        # Find the CSV file within the ZIP\n",
    "        csv_file_name = zip_ref.namelist()[0]\n",
    "        # Read the CSV file into a DataFrame df_scraped\n",
    "        with zip_ref.open(csv_file_name) as csv_file:\n",
    "            df_scraped = pd.read_csv(csv_file, sep=';', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"m-412710-831f51af70d6.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'storage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize GCP Storage Client\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m storage_client \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Specify GCP Storage Bucket and Model File Name\u001b[39;00m\n\u001b[1;32m      5\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m139m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'storage' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize GCP Storage Client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Specify GCP Storage Bucket and Model File Name\n",
    "bucket_name = \"139m\"\n",
    "model_file_name = \"139m_model\"\n",
    "model_blob_path = f\"gs://{bucket_name}/{model_file_name}\"\n",
    "print(model_blob_path)\n",
    "\n",
    "# # Download Model from GCP Storage\n",
    "# bucket = storage_client.get_bucket(bucket_name)\n",
    "# blob = bucket.blob(model_file_name)\n",
    "# blob.download_to_filename(model_file_name)\n",
    "\n",
    "# Load the Model during Startup\n",
    "# model = tf.keras.models.load_model(model_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Item(BaseModel):\n",
    "    data: list\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    num_results: int\n",
    "    cost_euros: float\n",
    "\n",
    "class OutputData(BaseModel):\n",
    "    list_1: list\n",
    "    list_2: list\n",
    "    list_3: list\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(item: Item):\n",
    "    try:\n",
    "        # Perform any necessary data preprocessing on item.data\n",
    "        # Make predictions using your loaded model\n",
    "        predictions = model.predict(tf.convert_to_tensor([item.data]))\n",
    "\n",
    "        # Return predictions as JSON\n",
    "        return JSONResponse(content={\"predictions\": predictions.tolist()})\n",
    "\n",
    "    except Exception as e:\n",
    "        return JSONResponse(content={\"error\": str(e)}, status_code=500)\n",
    "\n",
    "\n",
    "@app.post(\"/generate_numbers\", response_model=OutputData)\n",
    "def generate_numbers(data: InputData):\n",
    "    \n",
    "    #scrap\n",
    "    #load\n",
    "    #predict\n",
    "    #generate output\n",
    "\n",
    "    return OutputData(list_1=list_1, list_2=list_2, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
